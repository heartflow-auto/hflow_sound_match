#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ”¹è¿›ç‰ˆéŸ³ä¹åŒ¹é…æ¨¡å— - V2ç‰ˆæœ¬

ä¸»è¦æ”¹è¿›ï¼š
1. å¾ªç¯æ—¶ä½¿ç”¨æ·¡å…¥æ·¡å‡ºï¼Œä¿æŒè‡ªç„¶è¿‡æ¸¡ä¸”é•¿åº¦ä¸€è‡´
2. éŸ³ä¹åˆ‡æ¢æ—¶æ·»åŠ æ·¡å…¥æ·¡å‡ºæ•ˆæœ
3. æ”¯æŒå¯é…ç½®çš„è¿‡æ¸¡æ¨¡å¼

è¿‡æ¸¡ç­–ç•¥è¯´æ˜ï¼š
==============

ç­–ç•¥1ï¼šå¾ªç¯è¿‡æ¸¡ï¼ˆLoop Transitionï¼‰
--------------------------------
é—®é¢˜ï¼šéŸ³ä¹æ–‡ä»¶å¾ªç¯æ’­æ”¾æ—¶ï¼Œä»ç»“å°¾è·³å›å¼€å¤´ä¼šæœ‰çªå…€æ„Ÿ

åŸå§‹æ–¹æ¡ˆï¼ˆç›´æ¥è·³è½¬ï¼‰ï¼š
    [-----éŸ³ä¹æ–‡ä»¶-----]
    å–ç‰‡æ®µ:  |--10s--|
    å¾ªç¯å:         â†“ ç›´æ¥è·³è½¬
             |--10s--|  <- å¯èƒ½æœ‰çªå…€æ„Ÿ

æ”¹è¿›æ–¹æ¡ˆï¼ˆæ·¡å…¥æ·¡å‡ºï¼‰ï¼š
    [-----éŸ³ä¹æ–‡ä»¶-----]
    å–ç‰‡æ®µ:  |--10s--|
             æ·»åŠ æ·¡å‡º3s
    å¾ªç¯å:  |--10s--| (æœ€å3ç§’æ·¡å‡º)
             â†“
             |--10s--| (å‰3ç§’æ·¡å…¥)

ä¼˜ç‚¹ï¼š
- ä¿æŒ10ç§’é•¿åº¦ä¸å˜
- è¿‡æ¸¡è‡ªç„¶å¹³æ»‘
- å„å±‚é•¿åº¦ä¸€è‡´

ç¼ºç‚¹ï¼š
- éœ€è¦é¢å¤–å¤„ç†æ·¡å…¥æ·¡å‡º
- éŸ³é‡åœ¨è¿‡æ¸¡ç‚¹ä¼šç¨å¾®é™ä½


ç­–ç•¥2ï¼šéŸ³ä¹åˆ‡æ¢è¿‡æ¸¡ï¼ˆMusic Change Transitionï¼‰
--------------------------------------------
é—®é¢˜ï¼šå¿ƒç‡å˜åŒ–å¯¼è‡´L1/L2éŸ³ä¹åˆ‡æ¢æ—¶ï¼Œæ–°æ—§éŸ³ä¹ç›´æ¥åˆ‡æ¢ä¼šçªå…€

åŸå§‹æ–¹æ¡ˆï¼š
    æ—§éŸ³ä¹: |----------| (çªç„¶åœæ­¢)
    æ–°éŸ³ä¹:             |----------| (çªç„¶å¼€å§‹)

æ”¹è¿›æ–¹æ¡ˆAï¼ˆæ·¡å…¥æ·¡å‡ºï¼‰ï¼š
    æ—§éŸ³ä¹: |----------| (æœ€å3ç§’æ·¡å‡º)
    æ–°éŸ³ä¹:             |----------| (å‰3ç§’æ·¡å…¥)

æ”¹è¿›æ–¹æ¡ˆBï¼ˆäº¤å‰æ·¡åŒ–ï¼‰ï¼š
    æ—§éŸ³ä¹: |----------æ·¡å‡º--|
    æ–°éŸ³ä¹:       |--æ·¡å…¥----------|
              <-äº¤å‰3ç§’->

æœ¬å®ç°ä½¿ç”¨æ–¹æ¡ˆAï¼Œå› ä¸ºï¼š
- ä¿æŒç‰‡æ®µé•¿åº¦ä¸€è‡´
- å„å±‚åŒæ­¥æ›´ç®€å•
- æ€§èƒ½å¼€é”€æ›´å°


ç­–ç•¥3ï¼šç‰‡æ®µæ‹¼æ¥è¿‡æ¸¡ï¼ˆSegment Concatenationï¼‰
------------------------------------------
é—®é¢˜ï¼šè¿ç»­çš„10ç§’ç‰‡æ®µæ‹¼æ¥æ—¶ï¼Œæ‹¼æ¥ç‚¹å¯èƒ½æœ‰æ–­è£‚æ„Ÿ

æ–¹æ¡ˆï¼šç”±è°ƒç”¨è€…å†³å®š
- å®æ—¶æ’­æ”¾ï¼šç›´æ¥æ‹¼æ¥å³å¯ï¼ˆå•ä¸ªç‰‡æ®µå·²æœ‰æ·¡å…¥æ·¡å‡ºï¼‰
- å¯¼å‡ºå®Œæ•´éŸ³ä¹ï¼šä½¿ç”¨crossfadeæ‹¼æ¥ï¼ˆdemoä¸­çš„åšæ³•ï¼‰

"""

import os
import glob
import random
from pydub import AudioSegment
from dataclasses import dataclass
import numpy as np
import time
import math
from .compute import get_index_of_closest_heart_rate
from .memory import HeartMemory
from .utils import Emotion
from .utils import FilesHelper
from loguru import logger
from .config import cfg
from easydict import EasyDict


class RelaxMusicSessionV2:
    """
    æ”¹è¿›ç‰ˆéŸ³ä¹ä¼šè¯ç±» - æ”¯æŒè‡ªç„¶è¿‡æ¸¡

    æ–°å¢é…ç½®å‚æ•°ï¼š
        transition_mode: è¿‡æ¸¡æ¨¡å¼
            - 'fade': ä½¿ç”¨æ·¡å…¥æ·¡å‡ºï¼ˆæ¨èï¼Œé»˜è®¤ï¼‰
            - 'direct': ç›´æ¥åˆ‡æ¢ï¼ˆåŸå§‹æ–¹å¼ï¼‰
            - 'crossfade': äº¤å‰æ·¡åŒ–ï¼ˆä¼šæ”¹å˜é•¿åº¦ï¼‰

        loop_fade_enabled: æ˜¯å¦åœ¨å¾ªç¯æ—¶å¯ç”¨æ·¡å…¥æ·¡å‡º
        change_fade_enabled: æ˜¯å¦åœ¨åˆ‡æ¢éŸ³ä¹æ—¶å¯ç”¨æ·¡å…¥æ·¡å‡º
    """

    def __init__(self,
                 emotion=Emotion.peaceful,
                 args=None,
                 config=cfg,
                 transition_mode='fade'):
        self.config = config
        self.fade_in_time = self.fade_out_time = self.config['fade_time']
        self.transition_mode = transition_mode

        # åˆå§‹åŒ–L0ï¼ˆç¯å¢ƒéŸ³ï¼‰
        self.l0_file = self.init_l0_file()
        self.l0_sound = AudioSegment.from_file(self.l0_file)
        self.l0_faded = self.fade(self.l0_sound)

        # åˆå§‹åŒ–L1ã€L2
        self.l1_file = None
        self.l2_file = None
        self.l1_sound, self.l2_sound = None, None

        # åˆå§‹åŒ–çŠ¶æ€
        self.l0_state = EasyDict({"start": None, "end": None, 'next': None, 'should_fade_in': False})
        self.l1_state = EasyDict({"start": None, "end": None, 'next': None, 'should_fade_in': False})
        self.l2_state = EasyDict({"start": None, "end": None, 'next': None, 'should_fade_in': False})

        self.emotion = emotion
        self.hr_memory = HeartMemory(self.config['slide_window'])

    def fade(self, sound):
        """ç»™å®Œæ•´éŸ³é¢‘æ·»åŠ æ·¡å…¥æ·¡å‡º"""
        assert len(sound) / 1000 >= self.config['fade_time'], 'time of sound <= fade time configured'
        return sound.fade_in(1000 * self.fade_in_time).fade_out(1000 * self.fade_out_time)

    def match_by_layer(self, heart_rate, layer):
        """æ ¹æ®å¿ƒç‡åŒ¹é…æŒ‡å®šå±‚çº§çš„éŸ³ä¹æ–‡ä»¶"""
        emotion_folder = FilesHelper.get_emotion_root_by_emotion(self.emotion)
        emotion_fs, emotion_base_fs = FilesHelper.get_files_by_folder_root(emotion_folder)
        emotion_fs, emotion_base_fs = FilesHelper.get_files_by_layer(emotion_fs, emotion_base_fs, layer=layer)
        hrs = [i.split('_')[1] for i in emotion_base_fs]
        closest_inds = get_index_of_closest_heart_rate(heart_rate, hrs)
        closest_ind = random.choice(closest_inds)
        file = emotion_fs[closest_ind]
        return file

    def init_l0_file(self):
        """åˆå§‹åŒ–ç¯å¢ƒéŸ³æ–‡ä»¶"""
        return random.choice(FilesHelper.environment_files())

    def check_emotion(self, heart_rate, *args):
        return False

    def generate_l0_segment_and_update_l0(self, heart_rate):
        """ç”ŸæˆL0ï¼ˆç¯å¢ƒéŸ³ï¼‰ç‰‡æ®µ"""
        l0_varied = self.check_emotion(heart_rate)
        if l0_varied:
            ...
        else:
            l0_segment = self.simply_generate_next_sound_segment_and_update_state(0)
        return l0_segment

    def generate_l1_segment_and_update_l1(self, heart_rate):
        """
        ç”ŸæˆL1ï¼ˆä¸»æ—‹å¾‹ï¼‰ç‰‡æ®µ

        æ£€æŸ¥é€»è¾‘ï¼š
        1. å¦‚æœå‰©ä½™æ—¶é—´å……è¶³ï¼ˆ>2*transport_timeï¼‰ï¼Œç»§ç»­æ’­æ”¾
        2. å¦åˆ™ï¼Œæ›´æ–°åˆ°æ–°éŸ³ä¹
        """
        if self.l1_state['end'] is None:
            segment = self.simply_generate_next_sound_segment_and_update_state(1)
        else:
            rest = len(self.l1_sound) - self.l1_state['end']
            if rest > 2 * 1000 * self.config['transport_time']:
                segment = self.simply_generate_next_sound_segment_and_update_state(1)
            else:
                # å‰©ä½™æ—¶é—´ä¸è¶³ï¼Œæ›´æ–°éŸ³ä¹
                self.update_l1(heart_rate)
                segment = self.simply_generate_next_sound_segment_and_update_state(1)
        return segment

    def generate_l2_segment_and_update_l2(self, heart_rate):
        """
        ç”ŸæˆL2ï¼ˆå’Œå£°ï¼‰ç‰‡æ®µ

        æ›´æ–°è§„åˆ™ï¼š
        1. å¿ƒç‡æŒç»­é«˜äºå¹³å‡å€¼3æ¬¡
        2. å¿ƒç‡æ³¢åŠ¨å¹…åº¦è¶…è¿‡é˜ˆå€¼
        """
        if len(self.hr_memory['time']) > 0 and \
           max(self.hr_memory['time']) - min(self.hr_memory['time']) >= self.config['slide_window']:

            # è§„åˆ™1ï¼šå¿ƒç‡æŒç»­é«˜äºå¹³å‡å€¼
            if heart_rate > self.hr_memory.mean_hr:
                current_rule1_count = self.l2_state.get('larger_than_mean_hr', 0) + 1
                self.l2_state['larger_than_mean_hr'] = current_rule1_count
                if self.l2_state['larger_than_mean_hr'] >= 3:
                    self.update_l2(heart_rate)
                    self.l2_state['larger_than_mean_hr'] = 0

            # è§„åˆ™2ï¼šå¿ƒç‡æ³¢åŠ¨å¹…åº¦
            hrs_temp = self.hr_memory['hr'] + [heart_rate]
            amp = max(hrs_temp) - min(hrs_temp)

            if (65 <= heart_rate < 85 and amp > 4) or \
               (85 <= heart_rate < 105 and amp > 7) or \
               (heart_rate >= 105 and amp > 11):
                self.update_l2(heart_rate)

        segment = self.simply_generate_next_sound_segment_and_update_state(2)
        return segment

    def update_l1(self, heart_rate):
        """
        æ›´æ–°L1éŸ³ä¹

        æ”¹è¿›ï¼šæ·»åŠ æ·¡å…¥æ ‡è®°ï¼Œä¸‹ä¸€ä¸ªç‰‡æ®µä¼šæ·¡å…¥
        """
        logger.info(f"ğŸ”„ L1éŸ³ä¹åˆ‡æ¢ï¼šå¿ƒç‡={heart_rate} bpm")
        l1_file = self.match_by_layer(heart_rate, 1)
        self.l1_file = l1_file
        self.l1_sound = self.load_and_preprocess_sound(self.l1_file)
        # é‡ç½®çŠ¶æ€ï¼Œæ ‡è®°éœ€è¦æ·¡å…¥
        self.l1_state = EasyDict({
            "start": None,
            "end": None,
            'next': None,
            'should_fade_in': True  # æ–°å¢ï¼šæ ‡è®°ä¸‹ä¸€ä¸ªç‰‡æ®µéœ€è¦æ·¡å…¥
        })

    def update_l2(self, heart_rate):
        """æ›´æ–°L2éŸ³ä¹"""
        logger.debug(f"ğŸ”„ L2éŸ³ä¹åˆ‡æ¢ï¼šå¿ƒç‡={heart_rate} bpm")
        l2_file = self.match_by_layer(heart_rate, 2)
        self.l2_file = l2_file
        self.l2_sound = self.load_and_preprocess_sound(self.l2_file)
        # é‡ç½®çŠ¶æ€ï¼Œæ ‡è®°éœ€è¦æ·¡å…¥
        self.l2_state = EasyDict({
            "start": None,
            "end": None,
            'next': None,
            'should_fade_in': True
        })

    def simply_generate_next_sound_segment_and_update_state(self, layer):
        """
        ç”Ÿæˆä¸‹ä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µå¹¶æ›´æ–°çŠ¶æ€

        æ”¹è¿›çš„å¾ªç¯å’Œè¿‡æ¸¡é€»è¾‘ï¼š
        =====================

        1. æ­£å¸¸æƒ…å†µï¼šä»å½“å‰ä½ç½®å–10ç§’ç‰‡æ®µ
        2. å¾ªç¯æƒ…å†µï¼šä»å¤´å¼€å§‹ï¼Œå‰åéƒ½æ·»åŠ æ·¡å…¥æ·¡å‡º
        3. åˆ‡æ¢æƒ…å†µï¼šæ–°éŸ³ä¹çš„ç¬¬ä¸€ä¸ªç‰‡æ®µæ·»åŠ æ·¡å…¥

        å…³é”®æ”¹è¿›ï¼š
        - æ‰€æœ‰ç‰‡æ®µä¿æŒ10ç§’é•¿åº¦
        - ä½¿ç”¨æ·¡å…¥æ·¡å‡ºè€Œä¸æ˜¯crossfade
        - æ ¹æ®çŠ¶æ€æ ‡è®°å†³å®šæ˜¯å¦æ·»åŠ æ·¡å…¥
        """
        sound = {0: self.l0_sound, 1: self.l1_sound, 2: self.l2_sound}[layer]
        state = {0: self.l0_state, 1: self.l1_state, 2: self.l2_state}[layer]

        transport_time_ms = 1000 * self.config['transport_time']
        fade_time_ms = 1000 * self.config['fade_time']

        # ============ ç”Ÿæˆå½“å‰ç‰‡æ®µ ============
        if state['end'] is None:
            # ç¬¬ä¸€æ¬¡æ’­æ”¾
            start = 0
            end = transport_time_ms
            segment = sound[start:end]

            # å¦‚æœæ ‡è®°äº†éœ€è¦æ·¡å…¥ï¼ˆéŸ³ä¹åˆšåˆ‡æ¢ï¼‰ï¼Œæ·»åŠ æ·¡å…¥æ•ˆæœ
            if state.get('should_fade_in', False):
                segment = segment.fade_in(fade_time_ms)
                state['should_fade_in'] = False
                logger.debug(f"  Layer {layer}: æ·»åŠ æ·¡å…¥æ•ˆæœï¼ˆéŸ³ä¹åˆ‡æ¢ï¼‰")
        else:
            # ä½¿ç”¨é¢„å…ˆå‡†å¤‡å¥½çš„next segment
            assert state['next'] is not None, "next segment is None!"
            start = state['end']
            end = state['end'] + transport_time_ms
            segment = state['next']

        # ============ å‡†å¤‡ä¸‹ä¸€ä¸ªç‰‡æ®µ ============
        start_next = start + transport_time_ms
        end_next = end + transport_time_ms

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¾ªç¯
        if end_next >= len(sound):
            # éœ€è¦å¾ªç¯ï¼šä»å¤´å¼€å§‹
            logger.debug(f"  Layer {layer}: å¾ªç¯æ’­æ”¾ï¼ˆ{self.transition_mode}æ¨¡å¼ï¼‰")

            if self.transition_mode == 'fade':
                # æ–¹æ¡ˆï¼šä½¿ç”¨æ·¡å…¥æ·¡å‡º
                # å½“å‰ç‰‡æ®µæ·»åŠ æ·¡å‡ºï¼Œä¸‹ä¸€ä¸ªç‰‡æ®µæ·»åŠ æ·¡å…¥
                segment = segment.fade_out(fade_time_ms)

                # ä¸‹ä¸€ä¸ªç‰‡æ®µä»å¤´å¼€å§‹å¹¶æ·»åŠ æ·¡å…¥
                start_next = 0
                end_next = transport_time_ms
                segment_next = sound[start_next:end_next]
                segment_next = segment_next.fade_in(fade_time_ms)

            elif self.transition_mode == 'direct':
                # æ–¹æ¡ˆï¼šç›´æ¥å¾ªç¯ï¼ˆåŸå§‹æ–¹å¼ï¼‰
                start_next = 0
                end_next = transport_time_ms
                segment_next = sound[start_next:end_next]

            else:  # crossfadeæ¨¡å¼
                # æ³¨æ„ï¼šè¿™ä¼šæ”¹å˜segmenté•¿åº¦ï¼
                logger.warning(f"  Layer {layer}: crossfadeæ¨¡å¼ä¼šæ”¹å˜ç‰‡æ®µé•¿åº¦ï¼")
                start_next = 0
                end_next = transport_time_ms + fade_time_ms
                segment_next_temp = sound[start_next:end_next]
                # crossfadeä¼šåœ¨ä½¿ç”¨æ—¶å¤„ç†
                segment_next = segment_next_temp
        else:
            # æ­£å¸¸æƒ…å†µï¼šç»§ç»­æ’­æ”¾
            segment_next = sound[start_next:end_next]

        state['next'] = segment_next
        state['start'] = start
        state['end'] = end

        return segment

    def load_and_preprocess_sound(self, sound_file):
        """åŠ è½½å¹¶é¢„å¤„ç†éŸ³é¢‘æ–‡ä»¶"""
        sound = AudioSegment.from_file(sound_file)

        # éŸ³é‡å½’ä¸€åŒ–åˆ°-20dBFSï¼ˆé¿å…è¿‡å¤§æˆ–è¿‡å°ï¼‰
        # -20dBFSæ˜¯ä¸€ä¸ªåˆé€‚çš„ç›®æ ‡éŸ³é‡ï¼Œæ—¢ä¸ä¼šå¤ªå¤§ä¹Ÿä¸ä¼šå¤ªå°
        target_dBFS = -20.0
        change_in_dBFS = target_dBFS - sound.dBFS
        sound = sound.apply_gain(change_in_dBFS)

        # å¦‚æœæ–‡ä»¶å¤ªçŸ­ï¼Œå¾ªç¯ä¸€æ¬¡
        if len(sound) < 1000 * self.config['transport_time']:
            sound = sound.append(sound, crossfade=1000 * self.config['fade_time'])
        return sound

    def match_and_generate(self, heart_rate):
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šæ ¹æ®å¿ƒç‡åŒ¹é…å¹¶ç”ŸæˆéŸ³ä¹ç‰‡æ®µ

        è¿”å›ï¼š10ç§’çš„æ··åˆéŸ³é¢‘ç‰‡æ®µï¼ˆL0 + L1 + L2ï¼‰
        """
        # åˆå§‹åŒ–L1ã€L2ï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
        if self.hr_memory.is_empty or \
           (max(self.hr_memory['time']) - min(self.hr_memory['time']) < self.config['memory_min_time']):
            if self.l1_file is None:
                self.l1_file = self.match_by_layer(heart_rate, 1)
                self.l1_sound = self.load_and_preprocess_sound(self.l1_file)
            if self.l2_file is None:
                # ä¼˜å…ˆä½¿ç”¨ä¸L1ç›¸åŒBPMçš„L2æ–‡ä»¶
                if self.l1_file is not None:
                    potential_l2_file = self.l1_file.replace('_L1.mp3', '_L2.mp3')
                    if os.path.exists(potential_l2_file):
                        self.l2_file = potential_l2_file
                    else:
                        self.l2_file = self.match_by_layer(heart_rate, 2)
                else:
                    self.l2_file = self.match_by_layer(heart_rate, 2)
                self.l2_sound = self.load_and_preprocess_sound(self.l2_file)

        # ç”Ÿæˆå„å±‚ç‰‡æ®µ
        l0_segment = self.generate_l0_segment_and_update_l0(heart_rate)
        l1_segment = self.generate_l1_segment_and_update_l1(heart_rate)
        l2_segment = self.generate_l2_segment_and_update_l2(heart_rate)

        # éªŒè¯é•¿åº¦ä¸€è‡´
        assert len(l0_segment) == len(l1_segment) == len(l2_segment), \
            f"segments are different length! L0={len(l0_segment)}, L1={len(l1_segment)}, L2={len(l2_segment)}"

        # æ··åˆä¸‰å±‚éŸ³é¢‘ï¼ˆä½¿ç”¨éŸ³é‡æ§åˆ¶é¿å…è¿‡è½½ï¼‰
        # L0: ç¯å¢ƒéŸ³ï¼Œé™ä½6dBï¼ˆéŸ³é‡å‡åŠï¼‰
        # L1: ä¸»æ—‹å¾‹ï¼Œä¿æŒåŸéŸ³é‡
        # L2: å’Œå£°ï¼Œé™ä½3dB
        segment = l0_segment - 6  # ç¯å¢ƒéŸ³é™ä½
        segment = segment.overlay(l1_segment)  # ä¸»æ—‹å¾‹
        segment = segment.overlay(l2_segment - 3)  # å’Œå£°é™ä½

        # å¯¹æœ€ç»ˆæ··åˆç»“æœè¿›è¡ŒéŸ³é‡å½’ä¸€åŒ–ï¼Œé¿å…å‰Šæ³¢å¤±çœŸ
        # å½’ä¸€åŒ–åˆ°-14dBFSï¼ˆæ¯”å•è½¨ç•¥å“ï¼Œå› ä¸ºæ˜¯æ··åˆéŸ³é¢‘ï¼‰
        target_dBFS = -14.0
        change_in_dBFS = target_dBFS - segment.dBFS
        segment = segment.apply_gain(change_in_dBFS)

        # æ›´æ–°å¿ƒç‡è®°å¿†
        self.hr_memory.append(heart_rate)

        return segment


# ============ ä½¿ç”¨ç¤ºä¾‹ ============

def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    print("""
ä½¿ç”¨æ–¹æ³•ï¼š
=========

# æ–¹å¼1ï¼šä½¿ç”¨æ·¡å…¥æ·¡å‡ºï¼ˆæ¨èï¼Œé»˜è®¤ï¼‰
session = RelaxMusicSessionV2(emotion=Emotion.peaceful, transition_mode='fade')

# æ–¹å¼2ï¼šç›´æ¥åˆ‡æ¢ï¼ˆåŸå§‹æ–¹å¼ï¼‰
session = RelaxMusicSessionV2(emotion=Emotion.peaceful, transition_mode='direct')

# æ–¹å¼3ï¼šcrossfadeï¼ˆä¼šæ”¹å˜é•¿åº¦ï¼Œä¸æ¨èï¼‰
session = RelaxMusicSessionV2(emotion=Emotion.peaceful, transition_mode='crossfade')

# ç”ŸæˆéŸ³ä¹
segment = session.match_and_generate(75)  # 75 bpmå¿ƒç‡

è¿‡æ¸¡æ•ˆæœå¯¹æ¯”ï¼š
=============
- fadeæ¨¡å¼ï¼šå¾ªç¯ç‚¹æœ‰3ç§’æ·¡å…¥æ·¡å‡ºï¼ŒéŸ³é‡ä¼šç¨å¾®é™ä½ä½†å¾ˆè‡ªç„¶
- directæ¨¡å¼ï¼šç›´æ¥è·³è½¬ï¼Œå¯èƒ½æœ‰çªå…€æ„Ÿ
- crossfadeæ¨¡å¼ï¼šæœ€è‡ªç„¶ä½†ä¼šæ”¹å˜ç‰‡æ®µé•¿åº¦ï¼Œå¯èƒ½å¯¼è‡´åŒæ­¥é—®é¢˜
    """)


if __name__ == "__main__":
    example_usage()
